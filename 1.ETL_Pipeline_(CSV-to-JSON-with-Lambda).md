### Simple ETL Pipeline (CSV to JSON with Lambda)

#### Objective: Ingest a CSV uploaded to S3, convert it to JSON, and store the result in a processed bucket using AWS Lambda.



**Steps:**
#### 1. Created a S3 bucket called 'fake-users-bucket-1'

![Image](https://github.com/user-attachments/assets/4b15667e-02ed-4fe9-ab08-07d7156f5b11)




#### 2. Created two folders within the bucket and named the folder 'raw' and 'processed', this is where the raw data is going to be stored.

![Image](https://github.com/user-attachments/assets/511df5da-16dc-4169-8c97-e8162afd3c89)


![Image](https://github.com/user-attachments/assets/d1401af7-e97d-4b0f-9a01-c68e18d000fe)


![Image](https://github.com/user-attachments/assets/96a35923-2bca-46c6-81bb-81f0018b5133)



#### This where the JSON files will be stored.

![Image](https://github.com/user-attachments/assets/43c577d6-dd94-44a7-8f3f-941122a6494a)




#### Both folders are now created.

![Image](https://github.com/user-attachments/assets/2bf93233-65ff-493f-ae8f-33a7a0c49bbf)




#### 3. Uploaded a CSV file to the `s3://fake-users-bucket-1/raw/` folder, this is a csv containing 100 rows of realistic user data including user_id, name, email, signup_date and more.



![Image](https://github.com/user-attachments/assets/d3ee3872-7296-48a6-b7a0-1f39f9061c90)


![Image](https://github.com/user-attachments/assets/a7b3382c-a941-41a9-bf22-10eb84ec2210)


![Image](https://github.com/user-attachments/assets/e7fbbaf6-eda5-4350-a702-ce0c8be765b6)





#### I enabled bucket versioning to help prevent accidental deletion. 

![Image](https://github.com/user-attachments/assets/2f9d6882-af02-4c1c-9da1-3faf9de38c5b)



#### The file was uploaded successfully. 

![Image](https://github.com/user-attachments/assets/0c432bb9-387a-4827-ad5a-c6f398a50319)




#### 3. Created a Lambda function along with attaching IAM role with S3 permissions to it. 

![Image](https://github.com/user-attachments/assets/92f734ec-1713-4f87-aaa4-e09d4df3950c)

![Image](https://github.com/user-attachments/assets/e22e0b63-85eb-4c6b-b97c-e073a6423445)



#### I selected the 'Author from scratch' option, the architecture is 'x86' and the execution role as 'Create a new role with basic Lambda permissions'

![Image](https://github.com/user-attachments/assets/be75d6af-aa70-4258-8cd5-dccf56053315)

![Image](https://github.com/user-attachments/assets/3b872c8d-035c-4542-bf51-604ccebdc1b2)




#### 4. Added S3 Permissions to Lambda's Role

#### Lambda function home page -> configuration -> permissions -> click the link under execution role.

![Image](https://github.com/user-attachments/assets/1bb4f1d1-3329-4b6c-a63c-850a943307f2)




#### Add permissions -> Attach policies

![Image](https://github.com/user-attachments/assets/a8d81b66-a154-472e-a007-e9da1f961e68)




#### Attached 'AmazonS3ReadOnlyAccess' policy.

![Image](https://github.com/user-attachments/assets/1d1bad84-f2d7-4991-8cd0-596cc13ffe2c)


#### Then attached 'AWSLambdaBasicExecutionRole' policy.

![Image](https://github.com/user-attachments/assets/c83140f0-c0be-42da-8099-7abb38223dd5)







#### 5. Triggered a Lambda function via S3 event notification.

#### So I went to properties tab on my 'fake-users-bucket-1' S3 bucket.

![Image](https://github.com/user-attachments/assets/34c2fb56-8613-4538-b872-42062719c4b4)



#### Scrolled down to 'Event notifications' 

![Image](https://github.com/user-attachments/assets/8d44c062-2b82-49c3-a6eb-baace2b22ea4)



#### Named the notification along with suffix and prefix. Selected PUT as the event type, choose Lambda function as the destination and the Lambda function form the dropdown bellow.


![Image](https://github.com/user-attachments/assets/26544584-4578-45ef-823f-13f355331dea)


![Image](https://github.com/user-attachments/assets/add1c917-0d3b-4588-98f3-8e7afe09de26)


![Image](https://github.com/user-attachments/assets/41d039aa-c057-42f6-9877-d74becaaa6a6)




#### The event notification was successfully created. 

![Image](https://github.com/user-attachments/assets/7ddb0280-7c2b-421d-a873-7bf95a73f8b6)


#### In the Lambda function 'csvToJsonLambda' overview, I can see that the s3 bucket is now connected to the function. 

![Image](https://github.com/user-attachments/assets/e5ae446d-b2a9-41c0-b59d-52bc7a53cf23)





#### 6. Lambda uses Python + `boto3` to convert to JSON.

#### Replaced default code with the following code. Then deployed the code. 

![Image](https://github.com/user-attachments/assets/5a75f0a4-f935-4325-9cc5-eb818740c7d8)


#### Afterwards I headed back to execution role, and clicked the link which took me to IAM -> Roles


#### Created a inline policy.

![Image](https://github.com/user-attachments/assets/dedfcea7-5b26-464b-959f-d4866fc9feca)



#### Choose JSON format and enter the following code, and clicked next. 

![Image](https://github.com/user-attachments/assets/001fccd4-f131-485a-9e94-975f5b440b2b)

#### In the review and create tab, I named the policy 'LambdaS3Access' and click 'Create policy'

![Image](https://github.com/user-attachments/assets/1abb3641-094a-4d99-ac5c-da17997d3b87)



#### Now cloudwatch has logs on the lambda function 

![Image](https://github.com/user-attachments/assets/8b63e3d4-11c4-4dfb-ad24-087038792579) 


<br> 


#### 7. Stored transformed data in `s3://your-bucket/processed/`.


#### Downloaded the JSON file and decided to open it on my local machine via VScode to see the transformed data in a .JSON file.

![Image](https://github.com/user-attachments/assets/a59176d8-3f3b-49ca-8af8-842d7ce066f8)

![Image](https://github.com/user-attachments/assets/642bfb83-b377-42e0-a177-f0aecaeb845d)
