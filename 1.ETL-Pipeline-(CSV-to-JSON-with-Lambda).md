### Simple ETL Pipeline (CSV to JSON with Lambda)

#### Objective: Ingest a CSV uploaded to S3, convert it to JSON, and store the result in a processed bucket using AWS Lambda.


**Steps:**
1. Created a S3 bucket called 'fake-users-bucket-1'

![Image](https://github.com/user-attachments/assets/4b15667e-02ed-4fe9-ab08-07d7156f5b11)


2. Created a folder within the bucket and named the folder 'raw', this is where the raw data is going to be stored.

![Image](https://github.com/user-attachments/assets/511df5da-16dc-4169-8c97-e8162afd3c89)


![Image](https://github.com/user-attachments/assets/d1401af7-e97d-4b0f-9a01-c68e18d000fe)


![Image](https://github.com/user-attachments/assets/96a35923-2bca-46c6-81bb-81f0018b5133)


3. Uploaded a CSV file to the `s3://fake-users-bucket-1/raw/` folder,
this is a csv containing 100 rows of realistic user data including user_id, name, email, signup_date and more.


![Image](https://github.com/user-attachments/assets/d3ee3872-7296-48a6-b7a0-1f39f9061c90)

![Image](https://github.com/user-attachments/assets/a7b3382c-a941-41a9-bf22-10eb84ec2210)

![Image](https://github.com/user-attachments/assets/e7fbbaf6-eda5-4350-a702-ce0c8be765b6)

4. Triggered a Lambda function via S3 event notification.


5. Lambda uses Python + `boto3` to convert to JSON.
6. Stored transformed data in `s3://your-bucket/processed/`.
