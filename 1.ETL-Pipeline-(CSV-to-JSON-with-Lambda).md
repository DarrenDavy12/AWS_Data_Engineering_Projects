### Simple ETL Pipeline (CSV to JSON with Lambda)

#### Objective: Ingest a CSV uploaded to S3, convert it to JSON, and store the result in a processed bucket using AWS Lambda.



**Steps:**
1. Created a S3 bucket called 'fake-users-bucket-1'

![Image](https://github.com/user-attachments/assets/4b15667e-02ed-4fe9-ab08-07d7156f5b11)




2. Created two folders within the bucket and named the folder 'raw' and 'processed, this is where the raw data is going to be stored.

![Image](https://github.com/user-attachments/assets/511df5da-16dc-4169-8c97-e8162afd3c89)


![Image](https://github.com/user-attachments/assets/d1401af7-e97d-4b0f-9a01-c68e18d000fe)


![Image](https://github.com/user-attachments/assets/96a35923-2bca-46c6-81bb-81f0018b5133)




3. Uploaded a CSV file to the `s3://fake-users-bucket-1/raw/` folder,
this is a csv containing 100 rows of realistic user data including user_id, name, email, signup_date and more.


![Image](https://github.com/user-attachments/assets/d3ee3872-7296-48a6-b7a0-1f39f9061c90)

![Image](https://github.com/user-attachments/assets/a7b3382c-a941-41a9-bf22-10eb84ec2210)

![Image](https://github.com/user-attachments/assets/e7fbbaf6-eda5-4350-a702-ce0c8be765b6)



I enabled bucket versioning to help prevent accidental deletion. 

![Image](https://github.com/user-attachments/assets/2f9d6882-af02-4c1c-9da1-3faf9de38c5b)


The file was uploaded successfully. 
![Image](https://github.com/user-attachments/assets/0c432bb9-387a-4827-ad5a-c6f398a50319)




3. Created a Lambda function along with attaching IAM role with S3 permissions to it. 

![Image](https://github.com/user-attachments/assets/92f734ec-1713-4f87-aaa4-e09d4df3950c)

![Image](https://github.com/user-attachments/assets/e22e0b63-85eb-4c6b-b97c-e073a6423445)


I selected the 'Author from scratch', architecture is 'x86' and execution role as 'Create a new role with basic Lambda permissions'

![Image](https://github.com/user-attachments/assets/be75d6af-aa70-4258-8cd5-dccf56053315)

![Image](https://github.com/user-attachments/assets/3b872c8d-035c-4542-bf51-604ccebdc1b2)




4. Added S3 Permissions to Lambda's Role\

Lambda function home page -> configuration -> permissions -> click the link under execution role.

![Image](https://github.com/user-attachments/assets/1bb4f1d1-3329-4b6c-a63c-850a943307f2)




Add permissions -> Attach policies

![Image](https://github.com/user-attachments/assets/a8d81b66-a154-472e-a007-e9da1f961e68)




Attached 'AmazonS3ReadOnlyAccess' policy.

![Image](https://github.com/user-attachments/assets/1d1bad84-f2d7-4991-8cd0-596cc13ffe2c)


Then attached 'AWSLambdaBasicExecutionRole' policy.

![Image](https://github.com/user-attachments/assets/c83140f0-c0be-42da-8099-7abb38223dd5)







5. Triggered a Lambda function via S3 event notification.



So I went to properties tab on my 'fake-users-bucket-1' S3 bucket.

![Image](https://github.com/user-attachments/assets/34c2fb56-8613-4538-b872-42062719c4b4)



Scrolled down to 'Event notifications' 

![Image](https://github.com/user-attachments/assets/8d44c062-2b82-49c3-a6eb-baace2b22ea4)



Named the notification along with suffix and prefix. Selected PUT as the event type, choose Lambda function as the destination and the Lambda function form the dropdown bellow.


![Image](https://github.com/user-attachments/assets/26544584-4578-45ef-823f-13f355331dea)


![Image](https://github.com/user-attachments/assets/add1c917-0d3b-4588-98f3-8e7afe09de26)


![Image](https://github.com/user-attachments/assets/41d039aa-c057-42f6-9877-d74becaaa6a6)




The event notification was successfully created. 

![Image](https://github.com/user-attachments/assets/7ddb0280-7c2b-421d-a873-7bf95a73f8b6)



6. Created a custom inline policy for '/processed' folder.


6. Lambda uses Python + `boto3` to convert to JSON.





7. Stored transformed data in `s3://your-bucket/processed/`.
